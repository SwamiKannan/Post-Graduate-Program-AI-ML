{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pp68FAQf9aMN"
   },
   "source": [
    "# Sarcasm Detection\n",
    " **Acknowledgement**\n",
    "\n",
    "Misra, Rishabh, and Prahal Arora. \"Sarcasm Detection using Hybrid Neural Network.\" arXiv preprint arXiv:1908.07414 (2019).\n",
    "\n",
    "**Required Files given in below link.**\n",
    "\n",
    "https://drive.google.com/drive/folders/1xUnF35naPGU63xwRDVGc-DkZ3M8V5mMk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S3Wj_mIZ8S3K"
   },
   "source": [
    "## Install `Tensorflow2.0` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jW2Uk8otQvi8"
   },
   "outputs": [],
   "source": [
    "!!pip uninstall tensorflow\n",
    "!pip install tensorflow==2.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9kv9tyJ77eF"
   },
   "source": [
    "## Get Required Files from Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "D0O_n6OIEVyL",
    "outputId": "3d02fc9c-2fb9-4e05-d74a-a0f457b5e601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mgRpOvFMjKR"
   },
   "outputs": [],
   "source": [
    "#Set your project path \n",
    "project_path =  ## Add your path here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WXYwajPeQbRq"
   },
   "source": [
    "#**## Reading and Exploring Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vAk6BRUh8CqL"
   },
   "source": [
    "## Read Data \"Sarcasm_Headlines_Dataset.json\". Explore the data and get  some insights about the data. ( 4 marks)\n",
    "Hint - As its in json format you need to use pandas.read_json function. Give paraemeter lines = True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "StSLB-T8PuGr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6pXf7A78E2H"
   },
   "source": [
    "## Drop `article_link` from dataset. ( 2 marks)\n",
    "As we only need headline text data and is_sarcastic column for this project. We can drop artical link column here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLSVsvrlP9qD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0h6IOxU8OdH"
   },
   "source": [
    "## Get the Length of each line and find the maximum length. ( 4 marks)\n",
    "As different lines are of different length. We need to pad the our sequences using the max length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BRAsChZAQmr3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VPPd0YuPXi2M"
   },
   "source": [
    "#**## Modelling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "35abKfRx8as3"
   },
   "source": [
    "## Import required modules required for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVel73hYEV4r"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ziybaD1RdD9"
   },
   "source": [
    "# Set Different Parameters for the model. ( 2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPw9gAN_EV6m"
   },
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "maxlen = ## Add your max length here ##\n",
    "embedding_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9abSe-bM8fn9"
   },
   "source": [
    "## Apply Keras Tokenizer of headline column of your data.  ( 4 marks)\n",
    "Hint - First create a tokenizer instance using Tokenizer(num_words=max_features) \n",
    "And then fit this tokenizer instance on your data column df['headline'] using .fit_on_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T9Ad26HfTFMS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Ffi63KsST3P"
   },
   "source": [
    "# Define X and y for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnjxBdqmSS4s"
   },
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(df['headline'])\n",
    "X = pad_sequences(X, maxlen = maxlen)\n",
    "y = np.asarray(df['is_sarcastic'])\n",
    "\n",
    "print(\"Number of Samples:\", len(X))\n",
    "print(X[0])\n",
    "print(\"Number of Labels: \", len(y))\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJLyKg-98rH_"
   },
   "source": [
    "## Get the Vocabulary size ( 2 marks)\n",
    "Hint : You can use tokenizer.word_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-2w0gHEUUIo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5hjeMi40XcB1"
   },
   "source": [
    "#**## Word Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bUF1TuQa8ux0"
   },
   "source": [
    "## Get Glove Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vq5AIfRtMeZh"
   },
   "outputs": [],
   "source": [
    "glove_file = project_path + \"glove.6B.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJLX_n2WMecA"
   },
   "outputs": [],
   "source": [
    "#Extract Glove embedding zip file\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(glove_file, 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9IuXlu8-U3HG"
   },
   "source": [
    "# Get the Word Embeddings using Embedding file as given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elZ-T5aFGZmZ"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = './glove.6B.200d.txt'\n",
    "\n",
    "embeddings = {}\n",
    "for o in open(EMBEDDING_FILE):\n",
    "    word = o.split(\" \")[0]\n",
    "    # print(word)\n",
    "    embd = o.split(\" \")[1:]\n",
    "    embd = np.asarray(embd, dtype='float32')\n",
    "    # print(embd)\n",
    "    embeddings[word] = embd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bTPxveDmVCrA"
   },
   "source": [
    "# Create a weight matrix for words in training docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQgOhiywU9nU"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((num_words, 200))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "len(embeddings.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7IbWuEX82Ra"
   },
   "source": [
    "## Create and Compile your Model  ( 7 marks)\n",
    "Hint - Use Sequential model instance and then add Embedding layer, Bidirectional(LSTM) layer, then dense and dropout layers as required. \n",
    "In the end add a final dense layer with sigmoid activation for binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7jhsSgYXG4l"
   },
   "outputs": [],
   "source": [
    "### Embedding layer for hint \n",
    "## model.add(Embedding(num_words, embedding_size, weights = [embedding_matrix]))\n",
    "### Bidirectional LSTM layer for hint \n",
    "## model.add(Bidirectional(LSTM(128, return_sequences = True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJFMxZwMWoTw"
   },
   "source": [
    "# Fit your model with a batch size of 100 and validation_split = 0.2. and state the validation accuracy ( 5 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZpVkajCcWnRK"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 5\n",
    "\n",
    "## Add your code here ##"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Sarcasm_Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
